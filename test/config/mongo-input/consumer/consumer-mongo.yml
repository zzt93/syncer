version: 1.2

consumerId: mongo


input:
  masters:
    - connection:
        address: ${MONGO_IN}
        port: 27017
      scheduler: hash
      type: Mongo
      repos:
        - name: "simple_0"
          entities:
            - name: simple_type
              fields: [simples, nestedIn]


filter:
  - method: '
  public void filter(List<SyncData> list) {
    SyncData sync = list.get(0);
    for (Map simple : ((List<Map>) sync.getField("simples"))) {
      Long id = (Long) simple.get("id");
      Integer tinyint = (Integer) simple.get("tinyint");
      Long bigint = (Long) simple.get("bigint");
      byte[] bytes = (byte[]) simple.get("bytes");
      String varchar = (String) simple.get("varchar");
      BigDecimal decimal = (BigDecimal) simple.get("decimal");
      Double aDouble = (Double) simple.get("aDouble");
      org.bson.BsonTimestamp timestamp = (org.bson.BsonTimestamp) simple.get("timestamp");
    }
    Map nestedIn = (Map) sync.getField("nestedIn");
    Long id = (Long) nestedIn.get("id");
    Date time = (Date) nestedIn.get("time");
    String currency = (String) nestedIn.get("currency");
    String total = (String) nestedIn.get("total");
    Integer quantity = (Integer) nestedIn.get("quantity");
    Integer type = (Integer) nestedIn.get("type");
    String name = (String) nestedIn.get("name");
    String unit = (String) nestedIn.get("unit");
  }'



# Special expression
# "field.*"
# "field.*.flatten"
# "extra.*"
# "extra.*.flatten"

output:
  elasticsearch:
    connection:
      clusterName: ${ES_CLUSTER}
      clusterNodes: ["${ES_ADDR}:9300"]
    requestMapping: # mapping from input data to es request

      retryOnUpdateConflict: 3
      index: "repo + getExtra('suffix')" # default: repo

      fieldsMapping: # default: fields.*.flatten
        "fields": "fields.*.flatten"
    batch:
      size: 100
      delay: 1000
      maxRetry: 5
    refreshInMillis: 0
    failureLog:
      countLimit: 1000