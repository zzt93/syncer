version: 1.2

consumerId: code


input:
  masters:
  - connection:
      address: ${MYSQL_ADDR}
      port: 3306
    scheduler: mod
    repos:
    - name: "test.*"
      entities:
      - name: correctness
        fields: [time, news_id, currency, total] # default id is not null, other can be null
      - name: types
        fields: [tinyint, bigint, char, varchar, text, decimal, double, timestamp]
      - name: news
        fields: [plate_sub_type]
    - name: "simple"
      entities:
      - name: simple_type
        fields: [tinyint, bigint, char, varchar, text, decimal, double, timestamp]



filter:
  - method: 'public void filter(List<SyncData> list) {
             SyncData sync = list.get(0);
             if (!sync.updated()) {
               list.clear();
               return;
             }
             sync.addExtra("suffix", "");
             switch (sync.getEntity()) {
               case "news":
                 SyncUtil.toStr(sync, "thumb_content");
                 SyncUtil.toStr(sync, "content");
                 break;
               case "types":
               case "simple_type":
                 SyncUtil.toStr(sync, "text");
                 SyncUtil.unsignedByte(sync, "tinyint");
                 sync.addExtra("suffix", "-" + ((long) sync.getId())%2);
                 break;
               case "correctness":
                 SyncUtil.unsignedByte(sync, "type");
                 break;
             }
           }'



# Special expression
# "field.*"
# "field.*.flatten"
# "extra.*"
# "extra.*.flatten"

output:
  elasticsearch:
    connection:
      clusterName: ${ES_CLUSTER}
      clusterNodes: ["${ES_ADDR}:9300"]
    requestMapping: # mapping from input data to es request
      enableExtraQuery: true
      retryOnUpdateConflict: 3
      index: "repo + getExtra('target')" # default: repo
      documentId: "id" # default: id
      fieldsMapping: # default: fields.*.flatten
        "fields": "fields.*.flatten"
    batch:
      size: 100
      delay: 1000
      maxRetry: 5
    refreshInMillis: 0
    failureLog:
      countLimit: 1000
  mysql:
    connection:
      address: ${MYSQL_ADDR}
      port: 3306
      user: root
      password: ${MYSQL_PASS}
    rowMapping:
      schema: "repo"
      table: "entity + '_bak'"
      id: "id"
      rows:
        "fields": "fields.*.flatten"
        "id": "id"
    batch:
      size: 100
      delay: 100
      maxRetry: 5
    failureLog:
      countLimit: 1000