version: 1.2

consumerId: latest


input:
  masters:
    - connection:
        clusterNodes: [${MYSQL_ADDR}]
        autoOffsetReset: latest
      repos:
        - name: "test.*"
          entities:
            - name: correctness
              fields: [time, news_id, currency, total, quantity, type, name, unit] # default id is not null, other can be null
            - name: types
              fields: [tinyint, bigint, char, varchar, text, decimal, double, timestamp]
            - name: news
              fields: [title, content, thumb_content, tags, affair_id, modify_time, plate_type, state, alliance_id, number, plate_sub_type]
        - name: "simple.*"
          entities:
            - name: simple_type
              fields: [tinyint, bigint, char, varchar, text, decimal, double, timestamp]



filter:
  - method: 'public void filter(List<SyncData> list) {
               SyncData sync = list.get(0);
               sync.addExtra("suffix", "");
               switch (sync.getEntity()) {
                 case "news":
                   SyncUtil.toStr(sync, "thumb_content");
                   SyncUtil.toStr(sync, "content");
                   break;
                 case "types":
                 case "simple_type":
                   SyncUtil.toStr(sync, "text");
                   SyncUtil.unsignedByte(sync, "tinyint");
                   sync.addExtra("suffix", "-" + ((long) sync.getId())%2);
                   break;
                 case "correctness":
                   SyncUtil.unsignedByte(sync, "type");
                   break;
               }
             }'



# Special expression
# "field.*"
# "field.*.flatten"
# "extra.*"
# "extra.*.flatten"

output:
  elasticsearch:
    connection:
      clusterName: ${ES_CLUSTER}
      clusterNodes: ["${ES_ADDR}:9300"]
    requestMapping: # mapping from input data to es request

      retryOnUpdateConflict: 3
      index: "repo + getExtra('suffix')" # default: repo

      fieldsMapping: # default: fields.*.flatten
        "fields": "fields.*.flatten"
    batch:
      size: 100
      delay: 1000
      maxRetry: 5
    refreshInMillis: 0
    failureLog:
      countLimit: 1000